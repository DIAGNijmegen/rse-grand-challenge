{% load forge %}
"""
The following is a simple example algorithm.

It is meant to run within a container.

To run the container locally, you can call the following bash script:

  ./do_test_run.sh

This will start the inference and reads from ./test/input and writes to ./test/output

To save the container and prep it for upload to Grand-Challenge.org you can call:

  ./do_save.sh

Any container that shows the same behaviour will do, this is purely an example of how one COULD do it.

Reference the documentation to get details on the runtime environment on the platform:
https://grand-challenge.org/documentation/runtime-environment/

Happy programming!
"""
from pathlib import Path
import json
import torch

{% if object.algorithm_input_sockets|has_image_kind or object.algorithm_output_sockets|has_image_kind %}
from glob import glob
import numpy
{% endif %}
{% if object.algorithm_input_sockets|has_panimg_kind or object.algorithm_output_sockets|has_panimg_kind %}
import SimpleITK
{% endif %}
{% if object.algorithm_input_sockets|has_dicom_image_kind or object.algorithm_output_sockets|has_dicom_image_kind %}
import pydicom
{% endif %}

INPUT_PATH = Path("/input")
OUTPUT_PATH = Path("/output")
RESOURCE_PATH = Path("resources")

def run():
    # The key is a tuple of the slugs of the input sockets
    interface_key = get_interface_key()

    # Lookup the handler for this particular set of sockets (i.e. the interface)
    handler = {
    {% for interface_name, interface_key in object.algorithm_interface_names|zip:object.algorithm_interface_keys %}
    {{ interface_key }} : {{ interface_name }}_handler,
    {% endfor %}
    }[interface_key]

    # Call the handler
    return handler()

{% for interface_name, interface in object.algorithm_interface_names|zip:object.algorithm_interfaces %}
def {{ interface_name }}_handler():
    # Read the input
    {% for socket in interface.inputs %}
    {% if socket.is_dicom_image_kind %}
    input_{{ socket.slug|dash_to_underscore }} = load_dicom_image_set_as_array(
        location=INPUT_PATH / "{{ socket.relative_path }}",
    )
    {% elif socket.is_panimg_kind %}
    input_{{ socket.slug|dash_to_underscore }} = load_image_file_as_array(
        location=INPUT_PATH / "{{ socket.relative_path }}",
    )
    {% elif socket.is_json_kind %}
    input_{{ socket.slug|dash_to_underscore }} = load_json_file(
         location=INPUT_PATH / "{{ socket.relative_path }}",
    )
    {% elif socket.is_file_kind %}
    input_{{ socket.slug|dash_to_underscore }} = load_file(
         location=INPUT_PATH / "{{ socket.relative_path }}",
    )
    {% endif %}
    {% endfor %}

    # Process the inputs: any way you'd like, here we show-case torch
    _show_torch_cuda_info()

    # Example how to set torch to use the GPU (if available)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    model = torch.nn.Linear(10, 1).to(device)
    input = torch.randn(1, 10).to(device)
    output = model(input)

    # Your model will be extracted to the `model_dir` at runtime on Grand Challenge
    # Note: when testing locally, the local `./model` directory is mounted here.
    # Eventually, you should upload it as a tarball to Grand Challenge!
    # Go to Algorithm and upload it under Models.
    model_dir = Path("/opt/ml/model")
    with open(model_dir / "a_tarball_subdirectory" / "some_tarball_resource.txt", "r") as f:
        print(f.read())

    # For now, let us make bogus predictions
    {% for socket in interface.outputs %}
    output_{{ socket.slug|dash_to_underscore }} = {% spaceless %}
        {% if socket.has_example_value %}
            {% if socket.example_value|is_string %}
                "{{ socket.example_value }}"
            {% else %}
                {{ socket.example_value }}
            {% endif %}
        {% elif socket.is_panimg_kind %} numpy.eye(4, 2)
        {% elif socket.is_json_kind %} {"content": "should match the required format"}
        {% elif socket.is_file_kind %} "content: should match the required format"
        {% endif %}
        {% endspaceless %}
    {% endfor %}

    # Save your output
    {% for socket in interface.outputs %}
    {% if socket.is_panimg_kind %}
    write_array_as_image_file(
        location=OUTPUT_PATH / "{{ socket.relative_path }}",
        array=output_{{ socket.slug|dash_to_underscore }},
    )
    {% elif socket.is_json_kind %}
    write_json_file(
        location=OUTPUT_PATH / "{{ socket.relative_path }}",
        content=output_{{ socket.slug|dash_to_underscore }}
    )
    {% elif socket.is_file_kind %}
    write_file(
        location=OUTPUT_PATH / "{{ socket.relative_path }}",
        content=output_{{ socket.slug|dash_to_underscore }}
    )
    {% endif %}
    {% endfor %}
    return 0
{% endfor %}

def get_interface_key():
    # The inputs.json is a system generated file that contains information about
    # the inputs that interface with the algorithm
    inputs = load_json_file(
        location=INPUT_PATH / "inputs.json",
    )
    socket_slugs = [sv["socket"]["slug"] for sv in inputs]
    return tuple(sorted(socket_slugs))

def load_json_file(*, location):
    # Reads a json file
    with open(location, 'r') as f:
        return json.loads(f.read())

{% if object.algorithm_output_sockets|has_json_kind %}
def write_json_file(*, location, content):
    # Writes a json file
    with open(location, 'w') as f:
        f.write(json.dumps(content, indent=4))
{% endif %}

{% if object.algorithm_input_sockets|has_panimg_kind %}
def load_image_file_as_array(*, location):
    # Use SimpleITK to read a file
    input_files = glob(str(location / "*.tif")) + glob(str(location / "*.tiff")) + glob(str(location / "*.mha"))
    result = SimpleITK.ReadImage(input_files[0])

    # Convert it to a Numpy array
    return SimpleITK.GetArrayFromImage(result)
{% endif %}


{% if object.algorithm_input_sockets|has_dicom_image_kind %}
def load_dicom_image_set_as_array(*, location):
    # Get all DICOM files in the directory
    dicom_files = glob(str(location / "*.dcm"))

    # Read all slices
    slices = [pydicom.dcmread(f, force=True) for f in dicom_files]
    decompressed_slices = [slice.decompress() for slice in slices]

    # Extracting pixel-data is non-trivial:
    # - Slices need to be sorted in case of a 3D volume or 4D volume
    # - Pixel data will need to be decompressed, supporting different transfer syntaxes
    # - Any required transformations need to be performed (e.g. scaling via RescaleIntercept/RescaleSlope)
    # - ... et cetera
    # Please refer to Pydicom's documentation: https://pydicom.github.io/pydicom/1.1/pydicom_user_guide.html

    # Here we'll just return a null array with an approximately correct shape
    if len(dicom_files) > 2:
        result = numpy.array([[[0]]]) # 3D
    else:
        result = numpy.array([[0]]) # 2D

    return result
{% endif %}


{% if object.algorithm_output_sockets|has_panimg_kind %}
def write_array_as_image_file(*, location, array):
    location.mkdir(parents=True, exist_ok=True)

    # You may need to change the suffix to .tif to match the expected output
    suffix = ".mha"

    image = SimpleITK.GetImageFromArray(array)
    SimpleITK.WriteImage(
        image,
        location / f"output{suffix}",
        useCompression=True,
    )
{% endif %}


{% if object.algorithm_input_sockets|has_file_kind %}
# Note to the developer:
#   the following function is very generic and should likely
#   be adopted to something more specific for your algorithm/challenge
def load_file(*, location):
    # Reads the content of a file
    with open(location) as f:
        return f.read()
{% endif %}


{% if object.algorithm_output_sockets|has_file_kind %}
# Note to the developer:
#   the following function is very generic and should likely
#   be adopted to something more specific for your algorithm/challenge
def write_file(*, location, content):
    # Write the content to a file
    with open(location, 'w') as f:
        return f.write(content)
{% endif %}


def _show_torch_cuda_info():
    print("=+=" * 10)
    print("Collecting Torch CUDA information")
    print(f"Torch CUDA is available: {(available := torch.cuda.is_available())}")
    if available:
        print(f"\tnumber of devices: {torch.cuda.device_count()}")
        print(f"\tcurrent device: { (current_device := torch.cuda.current_device())}")
        print(f"\tproperties: {torch.cuda.get_device_properties(current_device)}")
    print("=+=" * 10)


if __name__ == "__main__":
    raise SystemExit(run())
